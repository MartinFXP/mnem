---
title: "Mixture Nested Effects Models  \n
Simultaneous inference of causal networks and corresponding subpopulations
from single cell perturbation data."
author: "Martin Pirkl, Niko Beerenwinkel"
date: "`r Sys.Date()`"
graphics: yes
output: BiocStyle::pdf_document
vignette: >
    %\VignetteIndexEntry{mnem}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
---

# Introduction

Single cell RNA-seq data sets from pooled CrispR screens provide the possibility
to analyze heterogeneous cell populations. We extended the original
Nested Effects Models (NEM) to Mixture Nested Effects Models (M\&NEM) to
simultaneously identify several causal signaling graphs and
corresponding subpopulations of cells. The final result will be a soft
clustering of the perturbed cells and a causal signaling graph, which
describes the interactions of the perturbed signaling genes (S-genes) for
each cluster of cells and the sub-topology for the observed genes (E-genes).

The M\&NEM algorithm uses an expectation maximization (EM) algorithm to
infer an optimum for $k$ components. In the E-step the expectation of
the hidden data (assignment of a cell to a component aka responsibilities)
is calculated. Based on the responsibilities M\&NEM weights the data for
each component and the standard NEM approach is used to optimize the
causal network for each weighted data set (M-step).

# Installation and loading
```{r global_options, include=FALSE}
knitr::opts_chunk$set(message=FALSE, out.width="125%", fig.align="center",
                      strip.white=TRUE, warning=FALSE, tidy=TRUE,
                      #out.extra='style="display:block; margin:auto;"',
                      fig.height = 4, fig.width = 8, error=FALSE)
fig.cap0 <- "Heatmap of the simulated log odds. Effects are blue and no effects
are red. Rows denote the observed E-genes and columns the S-genes. Each S-gene
has been perturbed in many cells. The E-genes are annotated as how they are
attached in the ground truth. E.g. E-genes named '1' are attached to S-gene
'1' in the ground truth."
fig.cap01 <- "Mixture NEM result for the simulated data. On top we show
the cell assignment percentages for hard clustering and the mixture weights.
The large circular vertices depict the S-genes, the small ones the
responsibility for the best fitting cell, the diamonds the number of assigned
cells and the boxes the number of assigned E-genes."
fig.cap02 <- "Ground truth causal networks of our simulated mixture of cells"
fig.cap03 <- "Model selection. Raw log likelihood of the models with different
components (left, blue) and penalized log likelihood (right, red)."
fig.cap04 <- "Responsibility distributions. Histograms of the responsibilities
for the best fitting model."
fig.cap05 <- "Heatmap of the simulated binary data. Effects are blue and no
effects
are white. Rows denote the observed E-genes and columns the S-genes. Each S-gene
has been perturbed in many cells. The E-genes are annotated as how they are
attached in the ground truth. E.g. E-genes named '1' are attached to S-gene
'1' in the ground truth."
fig.cap06 <- "Binary data. Mixture NEM result for a binary data set."
fig.cap5 <- "Penalized and raw log likelihood ratios. Blue denotes the raw
log likelihood and red the negative penalized for complexity."
fig.cap6 <- "Histograms of the responsibilities. The responsibilities for the
highest scoring mixture according to the penalized log likelihood."
fig.cap61 <- "Multiple perturbations. Simulated data including samples in
which more than one S-gene has been perturbed."
fig.cap62 <- "Multi sample result. The result of the mixture NEM inference
on data
including samples with multiple perturbations."
fig.cap7 <- "Highest scoring mixture for the Perturb-Seq dataset of cell
cycle regulators. On top we show
the cell assignments for hard clustering and the mixture weights. The large
circular vertices depict the S-genes, the small ones the responsibility for
the best fitting cell, the diamonds the number of assigned cells and the boxes
the number of assigned E-genes."
fig.cap8 <- "Second highest scoring mixture for the Perturb-Seq dataset of cell
cycle regulators. On top we show
the cell assignments for hard clustering and the mixture weights. The large
circular vertices depict the S-genes, the small ones the responsibility for
the best fitting cell, the diamonds the number of assigned cells and the boxes
the number of assigned E-genes."
paltmp <- palette()
paltmp[3] <- "blue"
paltmp[4] <- "brown"
palette(paltmp)
```
Install the package with the bioconductor manager package.
```{r, eval=FALSE}
if (!requireNamespace("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install("mnem")
```
Load the package with the library function.
```{r}
library(mnem)
```

# Small example

The input data is an m times n matrix of log odds (e.g. for fold changes as in
    the R package 'limma', Ritchie *et al.*, 2015). The *i*th row of
    the *j*th column are the log odds
    for feature (E-gene) i in cell j. As in the case of the original NEM, the
    data consists of a multitude of E-genes. However, where for the original
    NEM only one column complies to each perturbed signaling gene (S-gene),
    M\&NEM is designed for single cell data and therefore can handle and
    draws its power from multiple cells for each perturbed S-gene.

## Data simulation

The M\&NEM package includes a functions for the simulation of typical single
cell log odds. We use this function to create data for three S-genes and
    eight E-genes. Two E-genes for each S-gene and two uninformative E-genes.
    Additionally we generate the data from a mixture of two components
    and sample $100$ cells with different numbers of cells belonging
    to each component
    (approx. mixture weights: mw). The function simulates discrete data ($1$
    for effect and $0$ for no effect). We transform the discrete data to log
    odds by adding Gaussian noise with mean $1$ to all $1$s and with mean $-1$
    to all $0$s. Hint: If you use the 'mw' parameter, the 'Nems'
    parameter is not necessary.


Figure 1 shows a heatmap of our generated data. Since we used
only mild noise, effects and no effects are still clearly distinguished
into shades of blue and red. We can identify the uninformative E-gene
(no rownames) by its random/unique patterns. There is a clear
clustering noticeable for the knock-downs hinting at differential
causal regulation within the cell population. The E-gene numbers
denote the attachment of the E-genes in regards to the first
component. For the other components attachments differ and do not agree with the
E-gene name anymore.

```{r, fig.height=6, fig.width=10, fig.cap=fig.cap0}
seed <- 1234
Sgenes <- 3
Egenes <- 10
nCells <- 100
uninform <- 1
mw <- c(0.3, 0.3, 0.4)
Nems <- 3
noise <- 0.5
set.seed(seed)    
simmini <- simData(Sgenes = Sgenes, Egenes = Egenes,
                  Nems = Nems, mw = mw, nCells = nCells, uninform = uninform)
data <- simmini$data
ones <- which(data == 1)
zeros <- which(data == 0)
data[ones] <- rnorm(length(ones), 1, noise)
data[zeros] <- rnorm(length(zeros), -1, noise)
epiNEM::HeatmapOP(data, col = "RdBu", cexRow = 0.75, cexCol = 0.75,
                  bordercol = "transparent", xrot = 0, dendrogram = "both")
```
```{r, fig.cap=fig.cap02}
plot(simmini, data)
```

Figure 2 shows three different causal networks for the population
of simulated cells. The chosen mixture weights almost agree with the
noisy mixture weights due to only little noise.

## Network inference w.r.t. complexity

We forget the solution stored in 'simmini$Nem' and use the 'mnem' function to
   infer
   the network. We choose our a greedy search for the M-step and $3$
   independent starts for the EM algorithm to keep this vignette
   short. However, even for only three S-genes more starts are
   generally recommended.
   
   Since the number of components $k$ is a priori
   not known, we perform optimization for $k=1,2,3,4$ and use our penalized
   log likelihood to choose the best $k$. Figure 3 shows the best mixture of
   our causal networks with $k=3$. We have found the same causal
   networks we used to generate the data.
   
   We can speed up the computation with the 'parallel = n' parameter with
   $n$ threads.

```{r, fig.height=6, fig.width=14, fig.cap=fig.cap01}
starts <- 3
bestk <- mnemk(data, ks = 1:4, search = "greedy", starts = starts,
                       parallel = NULL)
plot(bestk$best)
```
```{r, fig.cap=fig.cap03}
par(mfrow=c(1,2)) 
plot(bestk$lls, col = "blue", main = "raw log likelihood", type = "b",
     xlab = "number of components", ylab = "score")
plot(bestk$ics, col = "red", main = "penalized log likelihood", type = "b",
     xlab = "number of components", ylab = "score")
```

We compare the actual log likelihood shown in figure 4 (left, blue)
to the penalized log likelihood
(right, red). Notice that the raw log likelihood of $k=4$ is higher
than for the $k=3$ component model. However, if we penalize complexity
the three component model gives us the best score (minimum). However,
the penalized like the raw log likelihood is not guaranteed to have
only a global, but can have several local optima. Hence, in practice
when there are little time constraints larger $k>4$ should also be tested.

## Cell responsibilities

Figure 5 shows the actual responsibilities of the best scoring
model. They denote how well each cell fits to each
component. e.g. when a cell has a responsibility of $100$\% for one
component, then the responsibility for the other two is $0$\%.

```{r, fig.cap=fig.cap04, fig.height = 4, fig.width = 4}
postprobs <- getAffinity(bestk$best$probs, mw = bestk$best$mw)
hist(postprobs, xlab = "responsibilities", main = "")
```

## Discrete data

For certain data sets calculating binary data (1 for effect and 0 for no effect)
might be more straightforward (e.g. Markowetz *et al*., 2005)
than log odds. Thus mixture NEM also supports discrete data as input for the EM
algorithm. To do inference on discrete data, we just have to set the method
parameter to "disc". However, for likelihood calculations we need to set
false positive and false negative rates. I.e. how many effects we assume are
coming from noise and how many real effects have been turned to zeros. These are
typically not known, but sometimes can be estimated. Although,
Markowetz *et al*., 2007 have shown, that the causal network is stable
across a variety of
different rates and only breaks down for very unreasonable (i.e. high)
values.

We choose false positive and false negative rates of $10\%$ each and apply
   them to our simulated data set.

```{r, fig.cap=fig.cap05, fig.height=6, fig.width=14}
set.seed(seed)
datadisc <- simmini$data
fp <- sample(which(datadisc == 0), floor(0.1*sum(datadisc == 0)))
fn <- sample(which(datadisc == 1), floor(0.1*sum(datadisc == 1)))
datadisc[c(fp,fn)] <- 1 - datadisc[c(fp,fn)]
epiNEM::HeatmapOP(datadisc, col = "RdBu", cexRow = 0.75, cexCol = 0.75,
                  bordercol = "transparent", xrot = 0, dendrogram = "both")
```

Similar to the log odds matrix, the structure of the simulated mixture of
causal networks is still recognizable even with the addition of our (mild)
noise. As a shortcut, we directly set the number of components to $3$.

```{r, fig.cap=fig.cap06, fig.height=6, fig.width=14}
result_disc <- mnem(datadisc, k = Nems, search = "greedy", starts = starts,
                        method = "disc", fpfn = c(0.1,0.1))
plot(result_disc)
```

## Multiple perturbations

Mixtures are in general very complex. Currently M\&NEM only supports the
standard NEM approach and no other extensions, which would increase complexity
even further. However, M\&NEM supports multiple perturbation per sample.
The information of multiple perturbations is not used to infer more complex
signaling structures like B-NEM (Pirkl *et al.*, 2016). M\&NEM just uses the
information to increase accuracy of the standard NEM approach. E.g. let's
assume during a knock-down of gene A genes E1 to E10 react and during a
knock-down of gene B genes E11 to E20 react. A sample with a perturbation of
genes A and B will show a reaction of genes E1 to E20 (assuming perfect data),
even though A and B are not linearly connected.

Again, we simulate data this time including $20\%$ double and $10\%$ triple
knock-downs. The inference is done the same way, except we specifically
tell the algorithm, that we have data with multiple perturbations with
'multi = TRUE'. Take a look at how the samples are named. The "_"
character separates different S-genes in the data column names.

```{r, fig.height=6, fig.width=10, fig.cap=fig.cap61}
set.seed(seed)
simmini2 <- simData(Sgenes = Sgenes, Egenes = Egenes,
                   Nems = Nems, mw = mw, nCells = nCells,
                   uninform = uninform, multi = c(0.2, 0.1))
data <- simmini2$data
ones <- which(data == 1)
zeros <- which(data == 0)
data[ones] <- rnorm(length(ones), 1, noise)
data[zeros] <- rnorm(length(zeros), -1, noise)
epiNEM::HeatmapOP(data, col = "RdBu", cexRow = 0.75, cexCol = 0.75,
                  bordercol = "transparent", dendrogram = "both")
```
```{r, fig.height=6, fig.width=10, fig.cap=fig.cap62}
result <- mnem(data, k = Nems, search = "greedy", multi = TRUE, starts = starts)
plot(result)
```

# Application to pooled CRISPR screens

We apply M\&NEM to three different data sets from two different pooled CRISPR
screens, Crop-seq (Datlinger *et al.*, 2017) and
Perturb-seq (Dixit *et al.*, 2016). Those screens consists of single
cell RNA-seq
data. Each cell has been perturbed by a knock-down of a gene
(S-gene) and each cell is observed by its gene expression profile
(E-genes).

We optimized the mixture for components $k=1,2,3,4,5$. Hence, we use our
penalized likelihood to find the optimal number of components without
over-fitting.

The data object 'app' consists of three lists containing the results
for Crop-seq, Perturb-seq (transcription factors) and Perturb-seq
(cell cycle regulators). Each list contains the results for
$k=1,2,3,4,5$ (number of components). See section 'Data generation'
for details.

## Cell cycle regulators (Perturb-seq)

As an example we show the results for the cell cycle regulators of the
Perturb-seq data set.
We show the raw log likelihood
together with the penalized likelihood. We choose the optimal $k$ at
the minimum of the penalized log likelihood.

```{r, fig.height = 3, fig.width = 4, fig.cap = fig.cap5}
data(app)
res2 <- app
maxk <- 5
j <- 2
res <- res2[[j]]
for (i in 2:5) {
    res[[i]]$data <- res[[1]]$data
}
bics <- rep(0, maxk)
ll <- rep(0, maxk)
for (i in seq_len(maxk)) {
    bics[i] <- getIC(res[[i]])
    ll[i] <- max(res[[i]]$ll)
}
ll2 <- ll
ll <- (ll/(max(ll)-min(ll)))*(max(bics)-min(bics))
ll <- ll - min(ll) + min(bics)
ll3 <- seq(min(bics), max(bics[!is.infinite(bics)]), length.out = 5)
par(mar=c(5,5,2,5))
plot(bics, type = "b", ylab = "", col = "red", xlab = "", yaxt = "n",
     ylim = c(min(min(bics,ll)), max(max(bics,ll))), xaxt = "n")
lines(ll, type = "b", col = "blue")
axis(4, ll3, round(seq(min(ll2), max(ll2), length.out = 5)), cex.axis = 0.5)
axis(2, ll3, round(ll3), cex.axis = 0.5)
axis(1, 1:maxk, 1:maxk)
mtext("penalized", side=2, line=3, cex = 1.2)
mtext("raw", side=4, line=3, cex = 1.2)
```

Figure 10 shows that the optimal mixture is $k=2$ according
to
our penalized log likelihood. Even $k=3$ beats just a single network.

Each cell has a certain probability (responsibility) to have been
generated by a components. The histograms show the distribution of
the responsibilities for all cells.

```{r, fig.height = 3, fig.width = 4, fig.cap = fig.cap6}
j <- 2
res <- res2[[j]]
for (i in 2:5) {
    res[[i]]$data <- res[[1]]$data
}
bics <- rep(0, maxk)
ll <- rep(0, maxk)
for (i in seq_len(maxk)) {
    bics[i] <- getIC(res[[i]])
    ll[i] <- max(res[[i]]$ll)
}
ll2 <- ll
ll <- (ll/(max(ll)-min(ll)))*(max(bics)-min(bics))
ll <- ll - min(ll) + min(bics)
ll3 <- seq(min(bics), max(bics[!is.infinite(bics)]), length.out = 5)
i <- which.min(bics)
gamma <- getAffinity(res[[i]]$probs, mw = res[[i]]$mw)
par(mar=c(5,5,2,5))
hist(gamma, main = "Histogram of responsibilities",
     xlab = "responsibilities")
```

Figure 11 shows the distribution of responsibilities.
There are  many cells with a responsibility of $100\%$, but many cells
have one around $50\%$ and are therefore ambiguous to which component they
belong.

We show the highest and second highest scoring mixtures. On
top is the percentage of cells assigned to each network by hard clustering
and the mixture weights. The connected large circles depict the causal
network of S-genes. The small circles show the responsibility of the best
fitting cell. The boxes show the number E-genes assigned to each S-gene and
the diamonds show the numbers of cells assigned to each S-gene. The NULL
node is assigned E-genes, which fit best to an S-gene (NULL) with no effects
at all.

```{r, fig.height = 10, fig.width = 20, fig.cap = fig.cap7, echo = FALSE}
j <- 2
res <- res2[[j]]
for (i in 2:5) {
    res[[i]]$data <- res[[1]]$data
}
bics <- rep(0, maxk)
ll <- rep(0, maxk)
for (i in seq_len(maxk)) {
    bics[i] <- getIC(res[[i]])
    ll[i] <- max(res[[i]]$ll)
}
ll2 <- ll
ll <- (ll/(max(ll)-min(ll)))*(max(bics)-min(bics))
ll <- ll - min(ll) + min(bics)
ll3 <- seq(min(bics), max(bics[!is.infinite(bics)]), length.out = 5)
i <- which.min(bics)
bics[i] <- bics[which.max(bics)]
i2 <- which.min(bics)
plot(res[[i]])
```
```{r, fig.height = 10, fig.width = 25, fig.cap = fig.cap8, echo = FALSE}
plot(res[[i2]])
```

The full methodology this package is based on, a simulation study and the
rest of our application are shown in Pirkl & Beerenwinkel (2018).

# Session information

```{r}
sessionInfo()
```

# Discrete data model

Log odds are a reasonable way for the data normalization, if the
perturbation experiments are accompanied by a single control (Pirkl \&
Beerenwinkel 2018). If the
experimental setup includes positive control (e.g. stimulated cells)
and negative control (unstimulated), discretizing the data to $0,1$ is
also feasible (Markowetz *et al.*, 2007). 

Let $\Phi$ be the transitively closed adjacency matrix of the causal
network connecting the S-genes and $\Theta$ the E-gene attachment with
$\theta_{ij} = 1$, if E-gene $j$ is attached to S-gene $i$. Let $\rho$
be the perturbation map with $\rho_{ij} = 1$, if cell $j$ has been
perturbed by a knock-down of S-gene $i$.

In the case of discrete data we need to account for false positives
and negatives with rates $\alpha$ and $\beta$. In this case we
calculate
the responsibilities by
\begin{equation*}
    \gamma_{ik} = \frac{\pi_k \prod\limits_{j=1}^m P\left(d_{ji} =
    a \mid f_{k,ij} = b\right)}{\sum\limits_s \pi_s
    \prod\limits_{j=1}^m P\left(d_{ji} = a \mid f_{s,ij} = b\right)}
\end{equation*}
with the discrete data $D = \left(d_{ij}\right)$, $F_k =
\rho^T\Phi_k\Theta_k = \left(f_{k,ij}\right)$ and
\begin{equation*}
    P\left(d_{ji} = a \mid f_{k,ij} = b\right) = \begin{cases}
    \alpha &\text{if } a = 1, b = 0\\
    1 - \alpha &\text{if } a = 0, b = 0\\
    \beta &\text{if } a = 0, b = 1\\
    1 - \beta &\text{if } a = 1, b = 1
\end{cases}.
\end{equation*}

Analogously we calculate the likelihood of the mixture by
\begin{equation}\label{mlh}
    \mathbf{\mathcal{L}} = \prod\limits_{i=1}^l \sum\limits_k \pi_k
    \prod\limits_{j=1}^m P\left(d_{ji} \mid f_{k,ij} \right).
\end{equation}

In contrast to the log odds we cannot just weight the data matrix by
the responsibilities. We use the following adjustment for the
conditional
probabilities during the optimization of $\Phi_k$ and $\Theta_k$.
\begin{equation*}
    P\left(d_{ji} \mid f_{k,ij} \right) = \gamma_{ik}\delta +
    \left(1-\gamma_{ik}\right)0.5
\end{equation*}

with $\delta \in \left\{\alpha, 1 - \alpha, \beta, 1 -
\beta\right\}$. Hence, the smaller the responsibility the closer the
conditional probability is to $0.5$ and the less influence the cell
has on the optimization.

If cells exist, which have been perturbed by a knock-down of more than
one S-gene, values greater than $1$ in $F_k$ have to be normalized to
$1$. This is independent of discrete or continuous data.

# References:

Datlinger, P., Rendeiro, A., Schmidl, C., Krausgruber, T., Traxler, P.,
Klughammer, J., Schuster, L. C., Kuchler, A., Alpar, D., and
Bock, C. (2017).
Pooled crispr screening with single-cell transcriptome readout.
Nature Methods, 14, 297-301.

Dixit, A., Parnas, O., Li, B., Chen, J., Fulco, C. P., Jerby-Arnon, L.,
Marjanovic, N. D., Dionne, D., Burks, T., Raychowdhury, R., Adamson,
B., Norman, T. M., Lander, E. S., Weissman, J. S., Friedman, N., and
Regev, A. (2016).
Perturb-seq: Dissecting molecular circuits with scalable single-cell rna
profiling of pooled genetic screens.
Cell, 167(7), 1853-1866.e17.

Markowetz, F., Bloch, J., and Spang, R. (2005). Non-transcriptional
pathway features reconstructed from secondary effects
of rna interference. Bioinformatics, 21(21), 4026–4032.

Markowetz, F., Kostka, D., Troyanskaya, O. G., and Spang, R. (2007).
Nested effects models for high-dimensional phenotyping
screens. Bioinformatics, 23(13), i305–i312.

Pirkl, M., Beerenwinkel, N.; Single cell network analysis with a mixture
of Nested Effects Models, Bioinformatics, Volume 34, Issue 17, 1 September 2018,
Pages i964–i971, https://doi.org/10.1093/bioinformatics/bty602.

Pirkl, M., Hand, E., Kube, D., Spang, R.; Analyzing synergistic and
non-synergistic interactions in signalling pathways using Boolean Nested Effect
Models, Bioinformatics, Volume 32, Issue 6, 15 March 2016, Pages 893–900,
https://doi.org/10.1093/bioinformatics/btv680

Ritchie ME, Phipson B, Wu D, Hu Y, Law CW, Shi W, Smyth GK (2015).
“limma powers differential expression analyses for RNA-sequencing and
microarray studies.” Nucleic Acids Research, 43(7), e47.

# Data Generation

The R code for generating the data object 'app' is shown in the
accompanying R file. It also includes the code for the simulations
from the method paper (Pirkl & Beerenwinkel 2018).

```{r, eval=FALSE, include=FALSE}
data <- read.csv("GSE92872_CROP-seq_Jurkat_TCR.digital_expression.csv",
                 stringsAsFactors = FALSE)
counts <- data[, grep("condition|^stim", colnames(data))]
counts <- counts[-(1:5), -1]
counts <- matrix(as.numeric(as.character(unlist(counts))), nrow(counts))
rownames(counts) <- data[6:nrow(data), 1]
colnames(counts) <- data[4, grep("^stim", colnames(data))]
colnames(counts)[which(colnames(counts) %in% "CTRL")] <- ""
data <- data[, -grep("DHODH|MVD|TUBB", colnames(data))]
save(data, file = "data.rda")
library(data.table)
data <- fread("k562_both_filt.txt")
data.backup <- data
data <- data[, -1]
data <- as.matrix(data)
rownames(data) <- data.backup$GENE
cn <- character(ncol(data))
for (i in seq_len(length(c2g[[1]]))) {
    cells <- unlist(strsplit(as.character(c2g[[2]][[i]]), ", "))
    cn[which(colnames(data) %in% cells)] <- paste(cn[
        which(colnames(data) %in% cells)],
        gsub("^c_|^c_sg|^m_|_[0-9]$|_10$", "",
             as.character(c2g[[1]][[i]])), sep = "_")
}
colnames(data) <- gsub("^_|^_p_sg|^_p_", "", cn)
data <- data[, -which(colnames(data) %in% "")]
pertdist <- unlist(lapply(colnames(data),
                          function(x)
                              return(length(unlist(strsplit(x, "_"))))))
hist(pertdist)
if (length(grep("_", colnames(data))) > 0) {
    data <- data[, -grep("_", colnames(data))]
}
save(data, file = "data.rda")
args <- commandArgs()
Sgenes <- as.numeric(gsub("Sgenes=", "", args[grep("Sgenes=", args)]))
run <- gsub("run=", "", args[grep("run=", args)])
noise <- gsub("noise=", "", args[grep("noise=", args)])
nem <- gsub("nem=", "", args[grep("nem=", args)])
if (length(grep(":", nem)) > 0) {
    nem <- as.numeric(gsub(":.*", "", nem)):as.numeric(gsub(".*:", "", nem))
} else {
    nem <- as.numeric(nem)
}
if (length(grep(":", noise)) > 0) {
    noise <- as.numeric(gsub(":.*", "", noise)):as.numeric(gsub(".*:", "",
                                                                noise))
} else {
    noise <- as.numeric(noise)
}
if (length(grep(":", run)) > 0) {
    run <- as.numeric(gsub(":.*", "", run)):as.numeric(gsub(".*:", "", run))
} else {
    run <- as.numeric(run)
}
library(cluster)
library(nem)
library(snowfall)
library(Rgraphviz)
library(mnem)
start1 <- as.numeric(format(Sys.time(), "%s"))
runs <- 100
noises <- c(1, 2.5, 5, 10)
nems <- 1:10
maxk <- 5
starts <- 10
search <- "modules"
verbose <- FALSE
Egenes <- 2
nCells <- 1000
simres <- array(0, c(runs, length(noises), length(nems), 4, 7),
                list(paste("run_", 1:runs, sep = ""),
                     paste("noise_", noises, sep = ""),
                     paste("components_", nems, sep = ""),
                     c("mnem", "nem", "cnem", "random2"),
                     c("time", "overfit", "accuracy", "sensitivity",
                       "specificity", "mixing", "mixing2")))

for (i in nem) {
    for (j in noise) {    
        if (file.exists(paste("simres_mnem_", Sgenes, "_", run, "_", j,
                              "_", i, ".rda", sep = ""))) {
            print(paste("simres_mnem_", Sgenes, "_", run, "_", j, "_",
                        i, ".rda", sep = ""))
            stop("simulation result already exists")
        }
    }
}
for (donoise in noise) {
    for (donem in nem) {
        print(paste(rep("_", 100), collapse = ""))
        print(paste("run", run))
        print(paste("noise", noises[donoise]))
        print(paste("nems", nems[donem]))
 
        mw <- runif(nems[donem], 0.1, 1)
        mw <- mw/sum(mw)
        sim <- simData(Sgenes = Sgenes, Egenes = Egenes, nCells = nCells,
                       Nems = nems[donem],
                       mw = mw, uninform = floor(Sgenes*Egenes*0.1))
        simfull <- NULL
        fullsim <- sim$Nem[[1]]*0
        for (i in seq_len(length(sim$Nem))) {
            tmp <- transitive.closure(sim$Nem[[i]], mat = TRUE)
            simfull <- cbind(simfull, t(tmp))
            fullsim <- fullsim + transitive.closure(sim$Nem[[i]], mat = TRUE)
        }
        fullsim[which(fullsim > 1)] <- 1
        diag(fullsim) <- 1
        
        data <- sim$data
        data <- (data - 0.5)/0.5
        data <- data + rnorm(length(sim$data), 0, noises[donoise])

        p <- NULL
        start <- as.numeric(format(Sys.time(), "%s"))
        res <- list()
        if (maxk == 1) {
            res <- mnem(data, starts = starts, search = search,
                        verbose = verbose)
        } else {
            bics <- rep(Inf, maxk)
            for (k in seq_len(maxk)) {
                res[[k]] <- mnem(data, starts = starts, search = search, k = k,
                                 verbose = verbose)
                bics[k] <- getIC(res[[k]])
            }
            res1 <- res[[1]]
            res <- res[[which.min(bics)]]
        }
        simres[run, donoise, donem, 1, 1] <-
            as.numeric(format(Sys.time(), "%s")) - start
        resfull <- NULL
        fullres <- res$comp[[1]]$phi*0
        for (i in seq_len(length(res$comp))) {
            tmp <- transitive.closure(res$comp[[i]]$phi, mat = TRUE)
            resfull <- cbind(resfull, t(tmp))
            fullres <- fullres + transitive.closure(res$comp[[i]]$phi,
                                                    mat = TRUE)
        }
        fullres[which(fullres > 1)] <- 1
        diag(fullres) <- 1

        if (dim(res$probs)[1] == 1) {
            mwbin <- 1
        } else {
            mwbin <- apply(apply(getAffinity(res$probs, mw = res$mw,
                                             affinity=0), 2,
                                 function(x) { xmax <- max(x)
                                     x[which(x != xmax)] <- 0
                                     x[which(x != 0)] <- 1
                                     return(x) }),
                           1, sum)/ncol(res$probs)
        }
        
        simres[run, donoise, donem, 1, 2] <- length(res$comp)/nems[donem]
        tp <- sum(fullres == 1 & fullsim == 1) - ncol(fullres)
        tn <- sum(fullres == 0 & fullsim == 0)
        fp <- sum(fullres == 1 & fullsim == 0)
        fn <- sum(fullres == 0 & fullsim == 1)
        simres[run, donoise, donem, 1, 4] <- tp/(tp+fn)
        simres[run, donoise, donem, 1, 5] <- tn/(tn+fp)
        simres[run, donoise, donem, 1, 3] <- hamSim(simfull, resfull)
        if (length(mw) == length(res$mw)) {
            simres[run, donoise, donem, 1, 6] <- sum(dist(rbind(sort(res$mw),
                                                                sort(mw))))
            simres[run, donoise, donem, 1, 7] <- sum(dist(rbind(sort(mwbin),
                                                                sort(mw))))
        }
        if (length(mw) > length(res$mw)) {
            simres[run, donoise, donem, 1, 6] <-
                sum(dist(rbind(sort(c(res$mw,
                                      rep(0,length(mw) - length(res$mw)))),
                               sort(mw))))
            simres[run, donoise, donem, 1, 7] <-
                sum(dist(rbind(sort(c(mwbin,
                                      rep(0, length(mw) - length(mwbin)))),
                               sort(mw))))
        }
        if (length(mw) < length(res$mw)) {
            simres[run, donoise, donem, 1, 6] <-
                sum(dist(rbind(sort(c(mw,
                                      rep(0, length(res$mw) - length(mw)))),
                               sort(res$mw))))
            simres[run, donoise, donem, 1, 7] <-
                sum(dist(rbind(sort(c(mw,
                                      rep(0, length(mwbin) - length(mw)))),
                               sort(mwbin))))
        }
        
        ## nem:
        start <- as.numeric(format(Sys.time(), "%s"))
        nemres <- mynem(data, search = search)
        simres[run, donoise, donem, 2, 1] <-
            as.numeric(format(Sys.time(), "%s")) - start
        if (maxk == 1) {
            fullnem <- transitive.closure(nemres$adj, mat = TRUE)
        } else {
            fullnem <- transitive.closure(res1$comp[[1]]$phi, mat = TRUE)
        }
        diag(fullnem) <- 1

        simres[run, donoise, donem, 2, 2] <- 1/nems[donem]
        tp <- sum(fullnem == 1 & fullsim == 1) - ncol(fullnem)
        tn <- sum(fullnem == 0 & fullsim == 0)
        fp <- sum(fullnem == 1 & fullsim == 0)
        fn <- sum(fullnem == 0 & fullsim == 1)
        simres[run, donoise, donem, 2, 4] <- tp/(tp+fn)
        simres[run, donoise, donem, 2, 5] <- tn/(tn+fp)
        simres[run, donoise, donem, 2, 3] <- hamSim(simfull, t(fullnem))
        simres[run, donoise, donem, 2, 6] <-
            sum(dist(rbind(sort(c(1, rep(0, length(mw) - 1))), sort(mw))))
        
        ## cluster NEM:
        start <- as.numeric(format(Sys.time(), "%s"))
        res <- clustNEM(data, search = search)
        simres[run, donoise, donem, 3, 1] <-
            as.numeric(format(Sys.time(), "%s")) - start
         resfull <- NULL
        fullres <- res$comp[[1]]$phi*0
        for (i in seq_len(length(res$comp))) {
            tmp <- transitive.closure(res$comp[[i]]$phi, mat = TRUE)
            resfull <- cbind(resfull, t(tmp))
            fullres <- fullres + transitive.closure(res$comp[[i]]$phi,
                                                    mat = TRUE)
        }
        fullres[which(fullres > 1)] <- 1
        diag(fullres) <- 1
        
        simres[run, donoise, donem, 4, 2] <- length(res$comp)/nems[donem]
        tp <- sum(fullrand == 1 & fullsim == 1) - ncol(fullrand)
        tn <- sum(fullrand == 0 & fullsim == 0)
        fp <- sum(fullrand == 1 & fullsim == 0)
        fn <- sum(fullrand == 0 & fullsim == 1)
        simres[run, donoise, donem, 4, 4] <- tp/(tp+fn)
        simres[run, donoise, donem, 4, 5] <- tn/(tn+fp)
        simres[run, donoise, donem, 4, 3] <- hamSim(simfull, fullrand)
        if (length(mw) == length(res$mw)) {
            simres[run, donoise, donem, 1, 6] <- sum(dist(rbind(sort(res$mw),
                                                                sort(mw))))
        }
        if (length(mw) > length(res$mw)) {
            simres[run, donoise, donem, 1, 6] <-
                sum(dist(rbind(sort(c(res$mw,
                                      rep(0, length(mw) - length(res$mw)))),
                               sort(mw))))
        }
        if (length(mw) < length(res$mw)) {
            simres[run, donoise, donem, 1, 6] <-
                sum(dist(rbind(sort(c(mw,
                                      rep(0, length(res$mw) - length(mw)))),
                               sort(res$mw))))
        }
    }
}

end1 <- as.numeric(format(Sys.time(), "%s"))

print(end1 - start1)

for (i in nem) {
    for (j in noise) {    
        save(simres, noises, nems, file = paste("temp/simres_mnem_", Sgenes,
                                                "_", run, "_", j, "_", i,
                                                ".rda", sep = ""))
    }
}

stop("simulations are done")

sim <- list()

count <- 0
for (Sgenes in c(3,5,10,20)) {
    simresF <- NULL
    for (i in seq_len(length(noises))) {
        for (j in seq_len(length(nems))) {
            for (k in seq_len(runs)) {
                if (file.exists(paste0("simres_mnem_", Sgenes, "_", k, "_",
                                       i, "_", j, ".rda"))) {
                    load(paste0("simres_mnem_", Sgenes, "_", k, "_", i,
                                "_", j, ".rda"))
                    if (is.null(simresF)) {
                        simresF <- simres
                    } else {
                        simresF[k,i,j,,] <- simres[k,i,j,,]
                    }
                }
            }
        }
    }
    assign(paste0("simres", Sgenes), simresF)
    count <- count + 1
    sim[[count]] <- simresF
}

library(mnem)
library(cluster)
library(nem)
library(Rgraphviz)

## define dataset

datasets <- c("cropseq", "perturbseq_cc7d", "perturbseq_p7d")
dataset <- datasets[1]

args <- commandArgs()

dataset <- gsub("dataset=", "", args[grep("dataset=", args)])

parallel <- gsub("cores=", "", args[grep("cores=", args)])

starts <- gsub("starts=", "", args[grep("starts=", args)])

run <- gsub("run=", "", args[grep("run=", args)])

dollr <- as.numeric(gsub("dollr=", "", args[grep("dollr=", args)]))

dobig <- as.numeric(gsub("dobig=", "", args[grep("dobig=", args)]))

dosmall <- as.numeric(gsub("dosmall=", "", args[grep("dosmall=", args)]))

addendum <- paste0("_run", run)

library(snowfall)

maxk <- 5

print(dataset)
print(dobig)
print(dosmall)
print(dollr)

if (donorm) {

    load(paste0(dataset, "_data.rda"))

    if (length(grep("perturbseq", dataset)) == 0) {

        exprslvl <- apply(data, 1, median)
        
        data <- data[which(exprslvl > 0), ]

        data <- t(t(data)/(colSums(data)/10000))

        data <- Linnorm(data)

        ## data <- log2(data + 0.5)
    
    } else {

        data <- exp(data) - 1

        exprslvl <- apply(data, 1, median)

        data <- data[which(exprslvl > 0), ]

        data <- Linnorm(data)

        colnames(data)[grep("INTER", colnames(data))] <- ""

        ## data <- log2(data + 0.5)

    }
    
    save(data, file = paste0(dataset, "_data_norm.rda"))

    print("norm done")

}

if (dollr) {

    load(paste0(dataset, "_data_norm.rda"))

    llr <- data*0

    C <- which(colnames(data) %in% "")

    distrPar <- function(i, data, C) {
        llrcol <- numeric(ncol(data))
        for (j in which(!(colnames(data) %in% ""))) {
            gene <- colnames(data)[j]
            D <- which(colnames(data) %in% gene)
            cdistr <- ecdf(data[i, C])
            ddistr <- ecdf(data[i, D])
            llrcol[j] <-
                log2(min(ddistr(data[i, j]),
                         1 - ddistr(data[i, j]))/min(cdistr(data[i,j]),
                                                     1 - cdistr(data[i,j])))
        }
        return(llrcol)
    }

    sfInit(parallel = TRUE, cpus = parallel)
    llr <- sfLapply(1:nrow(data), distrPar, data, C)
    llr <- do.call("rbind", llr)
    sfStop()

    llr[is.na(llr)] <- 0

    llr[is.infinite(llr)] <- max(llr[!is.infinite(llr)])

    colnames(llr) <- colnames(data)

    llr <- llr[, which(!(colnames(data) %in% ""))] # !!!

    rownames(llr) <- rownames(data)

    save(llr, file = paste0(dataset, "_llr.rda"))

    print("llr done")

}

if (dosmall) {

    load(paste0(dataset, "_kegg.rda"))
    load(paste0(dataset, "_llr.rda"))

    llr <- t(apply(llr, 1, function(x) {
        x[is.infinite(x)] <- max(x[!is.infinite(x)])
        return(x)
    }))

    colnames(llr) <- toupper(colnames(llr))

    if (length(grep("perturbseq", dataset)) == 0) {

        search <- "greedy"

        cropgenes <- c("LCK", "ZAP70", "PTPN6", "DOK2", "PTPN11", "EGR3", "LAT")
        
        lods <- llr[, which(colnames(llr) %in% cropgenes)]
        
    } else {

        search <- "greedy"
        
        lods <- llr
        
    }

    badgenes <- "Tcrlibrary"
    badgenes <- grep(badgenes, rownames(lods))

    if (length(badgenes) > 0) {
        lods <- lods[-badgenes, ]
    }

    sdev <- apply(lods, 1, sd)

    lods <- lods[which(sdev > sd(lods)), ]

    print(dim(lods))

    n <- length(unique(colnames(lods)))

    lods <- lods

    bics <- rep(Inf, maxk)

    res <- list()
    
    for (k in 1:maxk) {

        res[[k]] <- mnem(lods, starts = starts, parallel = parallel,
                         k = k, verbose = TRUE, converged = 10^-1,
                         search = search)
        
        res[[k]]$data <- NULL
        
        save(res, file = paste0(dataset, "_mnem_small", addendum, ".rda"))
        
    }
    
    save(res, file = paste0(dataset, "_mnem_small", addendum, ".rda"))

    stop("small set done")

}

datasets <- c("cropseq", "perturbseq_cc7d", "perturbseq_p7d")
dataset <- datasets[1]

maxk <- 5

starts <- 100

bigorsmall <- "small"

lls <- matrix(0, 5, starts)

llmins <- matrix(0, 5, starts)

resMax <- list()

for (i in seq_len(starts)) {
    print(i)
    if (file.exists(paste0(
                           dataset, "_mnem_", bigorsmall, "_run", i, ".rda"))) {
        load(paste0(
                    dataset, "_mnem_", bigorsmall, "_run", i, ".rda"))
    } else {
        next()
    }
    lls[1, i] <- res[[1]]$ll
    for (j in seq_len(min(maxk, length(res)))) {
        lls[j, i] <- res[[j]]$ll
        llmins[j, i] <- min(res[[j]]$limits[[1]]$ll)
        if (i == 1 | length(resMax) < j) {
            resMax[[j]] <- res[[j]]
        } else {
            if (resMax[[j]]$ll < res[[j]]$ll) {
                resMax[[j]] <- res[[j]]
            }
        }
    }
}

res <- resMax

res[[5]]$data <- res[[4]]$data <-
    res[[3]]$data <- res[[2]]$data <- res[[1]]$data <- lods

load(paste0(dataset, "_mnem_", bigorsmall, "_final.rda"))

cropres <- res

cc7dres <- res

p7dres <- res

res2 <- list(cropres, cc7dres, p7dres)

for (i in 1:3) {
    res2[[i]][[1]]$data <- res2[[i]][[1]]$data[1:2, ]
    for (j in 2:5) {
        res2[[i]][[j]]$data <- NULL
    }
}
```
