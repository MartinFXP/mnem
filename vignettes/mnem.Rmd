---
title: "Mixture Nested Effects Models  \n
Simultaneous inference of causal networks and corresponding subpopulations
from single cells perturbation data."
author: "Martin Pirkl, Niko Beerenwinkel"
date: "`r Sys.Date()`"
graphics: yes
output: BiocStyle::pdf_document
vignette: >
    %\VignetteIndexEntry{mnem}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
---

# Introduction

Single cell RNA-seq data sets from pooled CrispR screens provide the possibility
to analyze heterogeneous cell populations. We extended the original
Nested Effects Models (NEM) to Mixture Nested Effects Models (M\&NEM) to
simultaneously identify several causal signaling graphs and
corresponding subpopulations of cells. The final result will be a soft
clustering of the perturbed cells and a causal signaling graph, which
describes the interactions of the perturbed signaling genes (S-genes) for
each cluster of cells and the sub-topology for the observed genes (E-genes).

The M\&NEM algorithm uses an expectation maximization (EM) algorithm to
infer an optimum for $k$ components. In the E-step the expectation of
the hidden data (assignment of a cell to a component aka responsibilities)
is calculated. Based on the responsibilities M\&NEM weights the data for
each component and the standard NEM approach is used to optimize the
causal network for each weighted data set.

# Installation and loading
```{r global_options, include=FALSE}
knitr::opts_chunk$set(message=FALSE, out.width="125%", fig.align="center",
                      strip.white=TRUE, warning=FALSE, tidy=TRUE,
                      #out.extra='style="display:block; margin:auto;"',
                      fig.height = 4, fig.width = 8, error=FALSE)
fig.cap0 <- "Heatmap of the simulated log odds. Effects are blue and no effects
are red. Rows denote the observed E-genes and columns the S-genes. Each S-gene
has been perturbed in many cells. The E-genes are annotated as how they are
attached in the groudn truth. E.g. E-genes named '1' are attached to S-gene
'1' in the ground truth."
fig.cap01 <- "Mixture NEM result for the simulated data. On top we show
the cell assignment percentages for hard clustering and the mixture weights.
The large circular vertices depict the S-genes, the small ones the
responsibility for the best fitting cell, the diamonds the number of assigned
cells and the boxes the number of assigned E-genes."
fig.cap02 <- "Ground truth causal networks of our simulated mixture of cells"
fig.cap03 <- "Model selection. Raw log likelihood of the models with different
components (left, blue) and penalized log likelihood (right, red)."
fig.cap04 <- "Responsibility distributions. Histograms of the responsibilities
for the best fitting two component model (left) and the overfitting three
component model( right)."
fig.cap05 <- "Binary data. Mixture NEM result for a binary data set."
fig.cap1 <- "Accuracy of the inferred networks. The rows denote the number
of components of the ground truth (1 to 5). The accuracy of mixture NEMs is
shown in red, for a naive clustering approach in blue and for standard NEM
with one component in grey."
fig.cap2 <- "Accuracy of the inferred number of components. The rows denote
the number
of components of the ground truth (1 to 5). The accuracy of mixture NEMs is
shown in red, for a naive clustering approach in blue and for standard NEM
with one component in grey."
fig.cap3 <- "Accuracy of the mixture weights. The rows denote the number
of components of the ground truth (1 to 5). The accuracy of mixture NEMs is
shown in red, for a naive clustering approach in blue and for standard NEM
with one component in grey."
fig.cap4 <- "As a comparison to the inferred mixture weight we simulated
random mixture weights for different components."
fig.cap5 <- "Penalized and raw log likelihood ratios. Blue denotes the raw
log likelihood and red the negative penalized for complexity for the CROPSeq
(A) and the two PERTURBSeq datasets (B,C)."
fig.cap6 <- "Histograms of the responsibilities. The responsibilities for the
highest scoring according to the penalized log likelihood for the CROPSeq (A)
the two PERTURBSeq datasets (B,C)."
fig.cap7 <- "Highest scoring mixture for the CROPSeq dataset. On top we show
the cell assignments for hard clustering and the mixture weights. The large
circular vertices depict the S-genes, the small ones the responsibility for
the best fitting cell, the diamonds the number of assigned cells and the boxes
the number of assigned E-genes."
fig.cap8 <- "Second highest scoring mixture for the CROPSeq dataset. On top we
show the cell assignments for hard clustering and the mixture weights. The large
circular vertices depict the S-genes, the small ones the responsibility for
the best fitting cell, the diamonds the number of assigned cells and the boxes
the number of assigned E-genes."
fig.cap9 <- "Highest scoring mixture for the PERTURBSeq dataset of cell
cycle regulators. On top we show
the cell assignments for hard clustering and the mixture weights. The large
circular vertices depict the S-genes, the small ones the responsibility for
the best fitting cell, the diamonds the number of assigned cells and the boxes
the number of assigned E-genes."
fig.cap10 <- "Second highest scoring mixture for the PERTURBSeq dataset of cell
cycle regulators. On top we show
the cell assignments for hard clustering and the mixture weights. The large
circular vertices depict the S-genes, the small ones the responsibility for
the best fitting cell, the diamonds the number of assigned cells and the boxes
the number of assigned E-genes."
fig.cap11 <- "Highest scoring mixture for the PERTURBSeq dataset of
transcription factors. On top we show
the cell assignments for hard clustering and the mixture weights. The large
circular vertices depict the S-genes, the small ones the responsibility for
the best fitting cell, the diamonds the number of assigned cells and the boxes
the number of assigned E-genes."
fig.cap12 <- "Second highest scoring mixture for the PERTURBSeq dataset of
transcription factors. On top we show
the cell assignments for hard clustering and the mixture weights. The large
circular vertices depict the S-genes, the small ones the responsibility for
the best fitting cell, the diamonds the number of assigned cells and the boxes
the number of assigned E-genes."
paltmp <- palette()
paltmp[3] <- "blue"
paltmp[4] <- "brown"
palette(paltmp)
```
Install the package with the bioconductor function.
```{r, eval=FALSE}
source("https://bioconductor.org/biocLite.R")
biocLite("mnem")
```
Load the package with the library function.
```{r}
library(mnem)
```

# Mini example

The input data is an m times n matrix of log odds (e.g. for fold changes as in
    the R package "limma"). The *i*th row of the *j*th column are the log odds
    for feature (E-gene) i in cell j. As in the case of the original NEM, the
    data consists of a multitude of E-genes. However, where for the original
    NEM only one column complies to each perturbed signaling gene (S-gene),
    M\&NEM is designed for single cell data and therefore can handle and
    draws its power from multiple cells for each perturbed S-gene.

## Data simulation

The M\&NEM package includes a functions for the simulation of typical single
    cell log odds. We use this function to create data for three S-genes and
    eight E-genes. Two E-genes for each S-gene and two uninformative E-genes.
    Additionally we generate the data from a mixture of two components
    and sample $100$ cells, $20$ for one and $80$ for the other component
    (approx. mixture weights: mw). The function simulates discreet data ($1$
    for effect and $0$ for no effect). We transform the discreet data to log
    odds by adding Gaussian noise with mean $1$ to all $1$s and with mean $-1$
    to all $0$s. Figure 1 shows a heatmap of our generated data. Since we used
    only little noise, effects and no effects are still clearly distinguished
    into shades of blue and red. We can identify the uninformative E-genes
    (no rownames) by their random/unique patterns. Cells perturbed by S-gene
    $1$ all behave similarly. However, cells perturbed by S-genes $2$ and $3$
    fall into two clusters each hinting at differential causal regulation
    within the cell population.
```{r, fig.height=6, fig.width=10, fig.cap=fig.cap0}
set.seed(9247)    
simmini <- simData(Sgenes = 3, Egenes = 10,
                  Nems = 2, mw = c(0.2, 0.8), nCells = 100, uninform = 2)
data <- simmini$data
ones <- which(data == 1)
zeros <- which(data == 0)
data[ones] <- rnorm(length(ones), 1, 0.1)
data[zeros] <- rnorm(length(zeros), -1, 0.1)
epiNEM::HeatmapOP(data, col = "RdBu", cexRow = 0.75, cexCol = 0.75,
                  bordercol = "transparent", xrot = 0, dendrogram = "both")
```

## Network inference w.r.t. complexity

We forget the solution stored in 'sim$Nem' and use the 'mnem' function to infer
   the network. We choose our a greedy search for the M-step and $10$
   independent starts. Since the number of components $k$ is a priori
   not known, we perform optimization for $k=1,2,3$ and use our penalized
   log likelihood to choose the best $k$. Figure 2 shows the best mixture of
   our causal networks with $k=2$. We indeed have found the same causal
   networks we used to generate the data. Notice, that our input for the
   mixture weights is only an approximation, since the real mixture of the
   data is dependent on the ground truth networks (e.g. how similar they are)
   and noise.
```{r, fig.height=6, fig.width=14, fig.cap=fig.cap01}
mlist <- list()
mpen <- mllh <- numeric(3)
for (k in 1:3) {
    mlist[[k]] <- mnem(data, k = k, search = "greedy", runs = 10)
    mpen[k] <- getIC(mlist[[k]])
    mllh[k] <- mlist[[k]]$ll
}
plot(mlist[[which.min(mpen)]])
```
```{r, fig.cap=fig.cap02, out.width="75%"}
plot(simmini)
```

```{r, fig.cap=fig.cap03}
par(mfrow=c(1,2)) 
plot(mllh, col = "blue", main = "raw log likelihood", type = "b",
     xlab = "number of components", ylab = "score")
plot(mpen, col = "red", main = "penalized log likelihood", type = "b",
     xlab = "number of components", ylab = "score")
```

We look at the actual log likelihood (left, blue) compared to the penalized
(right, red), we see that the raw log likelihood is at least equally good
for the two and three component models. However, if we penalized complexity
the two component model gives us the best score (minimal). Even the one
component model beats the three component model due to complexity or lack
thereof, respectively.

## Cell responsibilities

Last but not least, we look at the actual rsponsibilities of the two and
three component models. While the two component model has very stable and
high responsibilities between $80$ and $100\%$, the three
component model's responsibilities are wildly distributed. and many cells
have ambiguous responsibilities around $50\%$. Due to its nature the two
component model's responsibilities also follow a symmetric distribution. 
```{r, fig.cap=fig.cap04}
par(mfrow=c(1,2))
postprobs <- getAffinity(mlist[[2]]$probs, mw = mlist[[2]]$mw)
hist(postprobs, xlab = "responsibilities", main = "")
postprobs <- getAffinity(mlist[[3]]$probs, mw = mlist[[3]]$mw)
hist(postprobs, xlab = "responsibilities", main = "")
```

## Discrete data

For certain data sets calculating binary data (1 for effect and 0 for no effect)
might be more straightforward (e.g. Markowetz et al., 2005)
than log odds. Thus mixture NEM also supports discrete data as input for the EM
algorithm. To do inference on discrete data, we just have to set the method
parameter to "disc". However, for likelihood calculations we need to set
false positive and false negative rates. I.e. how many effects we assume are
coming from noise and how many effects have been turned to zeros. These are
typically not known, but sometimes can be estimated. Although, Markowetz et al.,
2007 have shown, that the causal network is stable across a variety of
different rates and only breaks down for very unreasonable (i.e. high)
values.

```{r, fig.cap=fig.cap05, fig.height=6, fig.width=14}
datadisc <- simmini$data
fp <- sample(which(datadisc == 0), floor(0.1*sum(datadisc == 0)))
fn <- sample(which(datadisc == 1), floor(0.1*sum(datadisc == 1)))
datadisc[c(fp,fn)] <- 1 - datadisc[c(fp,fn)]
result_discrete <- mnem(datadisc, k = 2, search = "greedy", runs = 10,
                        method = "disc", fpfn = c(0.05,0.1))
plot(result_discrete)
```
 
# Simulations

We simulate cells based on a ground truth mixture of networks. We use M\&NEM to
infer an optimal network from the data and compare the result to the ground
truth. We also look at the accuracy of the mixture weights and the the number
of networks $k$. See also section 'Data generation' at the end of the vignette.
Simulation results are evaluated by accuracy of the networks, mixture
weights and number of components.

The data object 'sim' contains four lists with results of mixtures with
$3$, $5$, $10$ and $20$ S-genes. Each list consists of an array including $100$
runs for three different noise levels, five different numbers of
components $(1,2,3,4,5)$ and three different methods, which results in overall
$2400$ runs. For each run the array includes values for time,
over-fit, component accuracy (accuracy) and mixing weight accuracy
(mixing).

The different methods we compared are besides M\&NEM, the standard NEM approach
and a naive cluster approach (cNEM). For cNEM we first
cluster (k-means) all cells based on a correlation distance and then use the
standard NEM approach on each cluster.

We show the accuracy plots for for the components, number of components
and mixture weights.
```{r, fig.height=8, fig.width=10, fig.cap=fig.cap1}
data(sim)
noises <- c(1,2.5,5)
nems <- 1:5
simres3 <- sim[[1]]
simres5 <- sim[[2]]
simres10 <- sim[[3]]
simres20 <- sim[[4]]
meancol2 <- rgb(1,0,0)
meancol <- rgb(0,0,1)
redcol <- rgb(1,0,0)
bluecol <- rgb(0,0,1)
mar <- 1.5
par(mfrow=c(5,4),mar=rep(mar, 4),oma=c(3,5,3,0))
for (i in 1:5) {
    for (j in c(3,5,10,20)) {
        tmp <- get(paste0("simres", j))
        tmp2 <- NULL
        for (l in 1:3) {
            for (k in c(1,3,2)) {
                tmp3 <- tmp[,l,i,k,3]
                tmp2 <- cbind(tmp2, tmp3)
            }
        }
        boxplot(tmp2, col = rep(c(redcol, bluecol, "grey"), 3), xaxt = "n",
                ylim = c(0.5,1))
        abline(h=(5:10)/10, col = "grey", lty = 3)
        lines(1:ncol(tmp2), apply(tmp2, 2, mean), type = "p", col = meancol)
        lines(1:ncol(tmp2), apply(tmp2, 2, mean), type = "p", col = meancol2,
              pch = "*")
        axis(1, 1:(length(noises)*3), c(rep(1,3), rep(2.5,3),rep(5,3)))
        abline(v=c(length(noises)+c(0.5,length(noises)+0.5)), lty = 3,
               col = "black", lwd = 2)
    }
}
for (i in 1:5) {
    mtext(paste0("K=", i), side = 3, line = (40 - (i-1)*11.1), outer = FALSE,
          cex = 1, adj = 0,
          at = par("usr")[1] - (par("usr")[2]-par("usr")[1])*4)
}
Sgenes <- c(3,5,10,20)
for (i in 1:4) {
    mtext(paste0("n=", Sgenes[i]), side = 3, line = 46, outer = FALSE, cex = 1,
          adj = 0,
          at = par("usr")[1] - (par("usr")[2]-par("usr")[1])*(3.2 - (i-1)*1.2))
}
for (i in 1:4) {
    mtext(expression(sigma), side = 3, line = -12, outer = FALSE, cex = 1,
          adj = 0,
          at = par("usr")[1] - (par("usr")[2]-par("usr")[1])*(3.1 - (i-1)*1.2))
}
```
For the code of the latter two (only different array indices) see the R code
    of this vignette.
```{r, fig.height=8, fig.width=10, fig.cap=fig.cap2, echo=FALSE}
noises <- c(1,2.5,5)
nems <- 1:5
simres3 <- sim[[1]]
simres5 <- sim[[2]]
simres10 <- sim[[3]]
simres20 <- sim[[4]]
meancol2 <- rgb(1,0,0)
meancol <- rgb(0,0,1)
redcol <- rgb(1,0,0)
bluecol <- rgb(0,0,1)
mar <- 1.5
par(mfrow=c(5,4),mar=rep(mar, 4),oma=c(3,5,3,0))
for (i in 1:5) {
    for (j in c(3,5,10,20)) {
        tmp <- get(paste0("simres", j))
        tmp2 <- NULL
        for (l in 1:3) {
            for (k in c(1,3,2)) {
                tmp3 <- tmp[,l,i,k,2]
                tmp2 <- cbind(tmp2, tmp3)
            }
        }
        boxplot(tmp2, col = rep(c(redcol, bluecol, "grey"), 3), xaxt = "n")
        abline(h=seq(min(tmp2),max(tmp2),length.out=11), col = "grey", lty = 3)
        lines(1:ncol(tmp2), apply(tmp2, 2, mean), type = "p", col = meancol)
        lines(1:ncol(tmp2), apply(tmp2, 2, mean), type = "p", col = meancol2,
              pch = "*")
        axis(1, 1:(length(noises)*3), c(rep(1,3), rep(2.5,3),rep(5,3)))
        abline(v=c(length(noises)+c(0.5,length(noises)+0.5)), lty = 3,
               col = "black", lwd = 2)
    }
}
for (i in 1:5) {
    mtext(paste0("K=", i), side = 3, line = (40 - (i-1)*11.1), outer = FALSE,
          cex = 1, adj = 0,
          at = par("usr")[1] - (par("usr")[2]-par("usr")[1])*4)
}
Sgenes <- c(3,5,10,20)
for (i in 1:4) {
    mtext(paste0("n=", Sgenes[i]), side = 3, line = 46, outer = FALSE, cex = 1,
          adj = 0,
          at = par("usr")[1] - (par("usr")[2]-par("usr")[1])*(3.2 - (i-1)*1.2))
}
for (i in 1:4) {
    mtext(expression(sigma), side = 3, line = -12, outer = FALSE, cex = 1,
          adj = 0,
          at = par("usr")[1] - (par("usr")[2]-par("usr")[1])*(3.1 - (i-1)*1.2))
}
```
```{r, fig.height=8, fig.width=10, fig.cap=fig.cap3, echo=FALSE}
noises <- c(1,2.5,5)
nems <- 1:5
simres3 <- sim[[1]]
simres5 <- sim[[2]]
simres10 <- sim[[3]]
simres20 <- sim[[4]]
meancol2 <- rgb(1,0,0)
meancol <- rgb(0,0,1)
redcol <- rgb(1,0,0)
bluecol <- rgb(0,0,1)
mar <- 1.5
par(mfrow=c(5,4),mar=rep(mar, 4),oma=c(3,5,3,0))
for (i in 1:5) {
    for (j in c(3,5,10,20)) {
        tmp <- get(paste0("simres", j))
        tmp2 <- NULL
        for (l in 1:3) {
            for (k in c(1,3,2)) {
                tmp3 <- tmp[,l,i,k,6]
                tmp2 <- cbind(tmp2, tmp3)
            }
        }
        boxplot(tmp2, col = rep(c(redcol, bluecol, "grey"), 3), xaxt = "n",
                ylim = c(0,1))
        abline(h=seq(0,1,length.out=11), col = "grey", lty = 3)
        lines(1:ncol(tmp2), apply(tmp2, 2, mean), type = "p", col = meancol)
        lines(1:ncol(tmp2), apply(tmp2, 2, mean), type = "p", col = meancol2,
              pch = "*")
        axis(1, 1:(length(noises)*3), c(rep(1,3), rep(2.5,3),rep(5,3)))
        abline(v=c(length(noises)+c(0.5,length(noises)+0.5)), lty = 3,
               col = "black", lwd = 2)
    }
}
for (i in 1:5) {
    mtext(paste0("K=", i), side = 3, line = (40 - (i-1)*11.1), outer = FALSE,
          cex = 1, adj = 0,
          at = par("usr")[1] - (par("usr")[2]-par("usr")[1])*4)
}
Sgenes <- c(3,5,10,20)
for (i in 1:4) {
    mtext(paste0("n=", Sgenes[i]), side = 3, line = 46, outer = FALSE, cex = 1,
          adj = 0,
          at = par("usr")[1] - (par("usr")[2]-par("usr")[1])*(3.2 - (i-1)*1.2))
}
for (i in 1:4) {
    mtext(expression(sigma), side = 3, line = -12, outer = FALSE, cex = 1,
          adj = 0,
          at = par("usr")[1] - (par("usr")[2]-par("usr")[1])*(3.1 - (i-1)*1.2))
}
```

We randomly draw mixture weights and components as a comparison to our inferred
weights.
```{r, fig.width = 4, fig.height = 4, fig.cap = fig.cap4, out.width="60%"}
runs <- 100
maxk <- 5
mixrand <- matrix(0, runs, maxk)
for (j in 1:5) {
    nem <- j
    tmp <- numeric(runs)
    for (i in seq_len(runs)) {
        mw <- runif(nem, 0.1, 1)
        mw <- sort(mw/sum(mw))
        mw <- c(rep(0, 5 - length(mw)), mw)
        nem2 <- sample(1:5, 1)
        mw2 <- runif(nem2, 0.1, 1)
        mw2 <- sort(mw2/sum(mw2))
        mw2 <- c(rep(0, 5 - length(mw2)), mw2)
        tmp[i] <- dist(rbind(mw, mw2))
    }
    mixrand[, j] <- tmp
}
boxplot(mixrand, col = "grey", main = "random", xlab = "components K")
```

Figures 4-7 show that M\&NEM performs better as a random and the naive
clustering approach when it comes to overall accuracy of the
causal networks, number of components and mixture weights.

# Application to pooled CRISPR screens from CROPSeq and PERTURBSeq

We apply M\&NEM to three different data sets from two different pooled CRISPR
screens, CROPSeq (Datlinger *et al.*, 2017) and
PERTURBSeq (Dixit *et al.*, 2016). Those screens consists of single cell RNAseq
data. Each cell has been perturbed by a knock-down of a gene
(S-gene) and each cell is observed by its gene expression profile
(E-genes).

We optimized the mixture for components $k=1,2,3,4,5$. Hence, we use our
penalized likelihood to find the optimal number of components without
over-fitting.

The data object 'app' consists of three lists containing the results
for CROPSeq, PERTURBSeq (transcription factors) and PERTURBSeq
(cell cycle regulators). Each list contains the results for
$k=1,2,3,4,5$ (number of components). See section 'Data generation'
for details.

For each of the three data sets we show the raw log likelihood
together with the penalized likelihood. We choose the optimal $k$ at
the minimum of the penalized log likelihood.
```{r, fig.height = 3, fig.width = 11, fig.cap = fig.cap5}
data(app)
res2 <- app
maxk <- 5
par(mfrow=c(1,3), oma = c(0,0,1,0), mar = rep(0,4))
for (j in 1:3) {
    res <- res2[[j]]
    for (i in 2:5) {
        res[[i]]$data <- res[[1]]$data
    }
    bics <- rep(0, maxk)
    ll <- rep(0, maxk)
    for (i in seq_len(maxk)) {
        bics[i] <- getIC(res[[i]])
        ll[i] <- max(res[[i]]$ll)
    }
    ll2 <- ll
    ll <- (ll/(max(ll)-min(ll)))*(max(bics)-min(bics))
    ll <- ll - min(ll) + min(bics)
    ll3 <- seq(min(bics), max(bics[!is.infinite(bics)]), length.out = 5)
    par(mar=c(5,5,2,5))
    plot(bics, type = "b", ylab = "", col = "red", xlab = "", yaxt = "n",
         ylim = c(min(min(bics,ll)), max(max(bics,ll))), xaxt = "n")
    lines(ll, type = "b", col = "blue")
    axis(4, ll3, round(seq(min(ll2), max(ll2), length.out = 5)), cex.axis = 1.7)
    axis(2, ll3, round(ll3), cex.axis = 1.7)
    axis(1, 1:maxk, 1:maxk)
    mtext("penalized", side=2, line=3, cex = 1.2)
    mtext("raw", side=4, line=3, cex = 1.2)
    mtext(LETTERS[j], side = 3, line = -1, outer = FALSE, cex = 2.5, adj = 0,
          at = par("usr")[1] - (par("usr")[2]-par("usr")[1])*0.27)

}
```
Figure 10 shows that for each data set, the optimal mixture is $k=2$ according
to
our penalized log likelihood. However, while for the first and second
data set even $k=3$ beats just a single network, for the third data set
there is only weak evidence for a mixture of $k>1$.

Each cell has a certain probability (responsibility) to have been
generated by a components. The histograms show the distribution of
the responsibilities for all cells for the three data sets.
```{r, fig.height = 3, fig.width = 11, fig.cap = fig.cap6}
par(mfrow=c(1,3), oma = c(0,0,1,0), mar = rep(0,4))
for (j in 1:3) {
    res <- res2[[j]]
    for (i in 2:5) {
        res[[i]]$data <- res[[1]]$data
    }
    bics <- rep(0, maxk)
    ll <- rep(0, maxk)
    for (i in seq_len(maxk)) {
        bics[i] <- getIC(res[[i]])
        ll[i] <- max(res[[i]]$ll)
    }
    ll2 <- ll
    ll <- (ll/(max(ll)-min(ll)))*(max(bics)-min(bics))
    ll <- ll - min(ll) + min(bics)
    ll3 <- seq(min(bics), max(bics[!is.infinite(bics)]), length.out = 5)
    i <- which.min(bics)
    gamma <- getAffinity(res[[i]]$probs, mw = res[[i]]$mw)
    par(mar=c(5,5,2,5))
    hist(gamma, main = "Histogram of responsibilities",
         xlab = "responsibilities")
    mtext(LETTERS[j], side = 3, line = -2.3, outer = FALSE, cex = 2.5, adj = 0,
          at = par("usr")[1] - (par("usr")[2]-par("usr")[1])*0.27)
}
```
Figure 11 shows the distribution of responsibilities for all three data sets.
The responsibilities for the first data set are almost binary, i.e.
almost each cell belongs to $100\%$ to one mixture component. For the
other two data sets there is a much more smooth transition. While
there are still many cells with a responsibility of $100\%$, many cells
have one around $50\%$. For the third data set even more cells have
responsibilities between $40\%$ and $50\%$. This is in accordance to the
penalized log likelihood and is evidence, that the two mixture
components are very similar and most of the causal network is stable
across cells.

We show the highest and second highest scoring networks for each data set. On
top is the percentage of cells assigned to each network by hard clustering
and the mixture weights. The connected large circles depict the causal
network of S-genes. The small circles show the responsibility of the best
fitting cell. The boxes show the number E-genes assigned to each S-gene and
the diamonds show the numbers of cells assigned to each S-gene. The NULL
node is assigned E-genes, which fit best to an S-gene (NULL) with no effects
at all. For the R code of the second and third data sets see the accompanyning
R file (only the "j <- 1" needs to be changed to 2 or 3).
```{r, fig.height = 8, fig.width = 16, fig.cap = fig.cap7}
j <- 1
res <- res2[[j]]
for (i in 2:5) {
    res[[i]]$data <- res[[1]]$data
}
bics <- rep(0, maxk)
ll <- rep(0, maxk)
for (i in seq_len(maxk)) {
    bics[i] <- getIC(res[[i]])
    ll[i] <- max(res[[i]]$ll)
}
ll2 <- ll
ll <- (ll/(max(ll)-min(ll)))*(max(bics)-min(bics))
ll <- ll - min(ll) + min(bics)
ll3 <- seq(min(bics), max(bics[!is.infinite(bics)]), length.out = 5)
i <- which.min(bics)
bics[i] <- bics[which.max(bics)]
i2 <- which.min(bics)
plot(res[[i]])
```
```{r, fig.height = 8, fig.width = 20, fig.cap = fig.cap7}
plot(res[[i2]])
```
```{r, fig.height = 10, fig.width = 20, fig.cap = fig.cap7, echo = FALSE}
j <- 2
res <- res2[[j]]
for (i in 2:5) {
    res[[i]]$data <- res[[1]]$data
}
bics <- rep(0, maxk)
ll <- rep(0, maxk)
for (i in seq_len(maxk)) {
    bics[i] <- getIC(res[[i]])
    ll[i] <- max(res[[i]]$ll)
}
ll2 <- ll
ll <- (ll/(max(ll)-min(ll)))*(max(bics)-min(bics))
ll <- ll - min(ll) + min(bics)
ll3 <- seq(min(bics), max(bics[!is.infinite(bics)]), length.out = 5)
i <- which.min(bics)
bics[i] <- bics[which.max(bics)]
i2 <- which.min(bics)
plot(res[[i]])
```
```{r, fig.height = 10, fig.width = 25, fig.cap = fig.cap7, echo = FALSE}
plot(res[[i2]])
```
```{r, fig.height = 8, fig.width = 16, fig.cap = fig.cap7, echo = FALSE}
j <- 3
res <- res2[[j]]
for (i in 2:5) {
    res[[i]]$data <- res[[1]]$data
}
bics <- rep(0, maxk)
ll <- rep(0, maxk)
for (i in seq_len(maxk)) {
    bics[i] <- getIC(res[[i]])
    ll[i] <- max(res[[i]]$ll)
}
ll2 <- ll
ll <- (ll/(max(ll)-min(ll)))*(max(bics)-min(bics))
ll <- ll - min(ll) + min(bics)
ll3 <- seq(min(bics), max(bics[!is.infinite(bics)]), length.out = 5)
i <- which.min(bics)
bics[i] <- bics[which.max(bics)]
i2 <- which.min(bics)
plot(res[[i]])
```
```{r, fig.height = 8, fig.width = 8, fig.cap = fig.cap7, echo = FALSE}
plot(res[[i2]])
```

# Session information

```{r}
sessionInfo()
```

# References:

Martin Pirkl, Niko Beerenwinkel (2018).  
Single cell network analysis with a mixture of Nested Effects Models  
bioRxiv 258202; doi: https://doi.org/10.1101/258202  

Datlinger, P., Rendeiro, A., Schmidl, C., Krausgruber, T., Traxler, P.,
Klughammer, J., Schuster, L. C., Kuchler, A., Alpar, D., and
Bock, C. (2017).
Pooled crispr screening with single-cell transcriptome readout.  
Nature Methods, 14, 297-301.

Dixit, A., Parnas, O., Li, B., Chen, J., Fulco, C. P., Jerby-Arnon, L.,
Marjanovic, N. D., Dionne, D., Burks, T., Raychowdhury, R., Adamson,
B., Norman, T. M., Lander, E. S., Weissman, J. S., Friedman, N., and
Regev, A. (2016).  
Perturb-seq: Dissecting molecular circuits with scalable single-cell rna
profiling of pooled genetic screens.  
Cell, 167(7), 1853-1866.e17.

# Data Generation

The R code for generating the data objects 'sim' and 'app' is shown
in the accompanying R file.

```{r, eval=FALSE, include=FALSE}
data <- read.csv("GSE92872_CROP-seq_Jurkat_TCR.digital_expression.csv",
                 stringsAsFactors = FALSE)
counts <- data[, grep("condition|^stim", colnames(data))]
counts <- counts[-(1:5), -1]
counts <- matrix(as.numeric(as.character(unlist(counts))), nrow(counts))
rownames(counts) <- data[6:nrow(data), 1]
colnames(counts) <- data[4, grep("^stim", colnames(data))]
colnames(counts)[which(colnames(counts) %in% "CTRL")] <- ""
data <- data[, -grep("DHODH|MVD|TUBB", colnames(data))]
save(data, file = "data.rda")
library(data.table)
data <- fread("k562_both_filt.txt")
data.backup <- data
data <- data[, -1]
data <- as.matrix(data)
rownames(data) <- data.backup$GENE
cn <- character(ncol(data))
for (i in seq_len(length(c2g[[1]]))) {
    cells <- unlist(strsplit(as.character(c2g[[2]][[i]]), ", "))
    cn[which(colnames(data) %in% cells)] <- paste(cn[
        which(colnames(data) %in% cells)],
        gsub("^c_|^c_sg|^m_|_[0-9]$|_10$", "",
             as.character(c2g[[1]][[i]])), sep = "_")
}
colnames(data) <- gsub("^_|^_p_sg|^_p_", "", cn)
data <- data[, -which(colnames(data) %in% "")]
pertdist <- unlist(lapply(colnames(data),
                          function(x)
                              return(length(unlist(strsplit(x, "_"))))))
hist(pertdist)
if (length(grep("_", colnames(data))) > 0) {
    data <- data[, -grep("_", colnames(data))]
}
save(data, file = "data.rda")
args <- commandArgs()
Sgenes <- as.numeric(gsub("Sgenes=", "", args[grep("Sgenes=", args)]))
run <- gsub("run=", "", args[grep("run=", args)])
noise <- gsub("noise=", "", args[grep("noise=", args)])
nem <- gsub("nem=", "", args[grep("nem=", args)])
if (length(grep(":", nem)) > 0) {
    nem <- as.numeric(gsub(":.*", "", nem)):as.numeric(gsub(".*:", "", nem))
} else {
    nem <- as.numeric(nem)
}
if (length(grep(":", noise)) > 0) {
    noise <- as.numeric(gsub(":.*", "", noise)):as.numeric(gsub(".*:", "",
                                                                noise))
} else {
    noise <- as.numeric(noise)
}
if (length(grep(":", run)) > 0) {
    run <- as.numeric(gsub(":.*", "", run)):as.numeric(gsub(".*:", "", run))
} else {
    run <- as.numeric(run)
}
library(cluster)
library(nem)
library(snowfall)
library(Rgraphviz)
library(mnem)
start1 <- as.numeric(format(Sys.time(), "%s"))
runs <- 100
noises <- c(1, 2.5, 5, 10)
nems <- 1:10
maxk <- 5
starts <- 10
search <- "modules"
verbose <- FALSE
Egenes <- 2
nCells <- 1000
simres <- array(0, c(runs, length(noises), length(nems), 4, 7),
                list(paste("run_", 1:runs, sep = ""),
                     paste("noise_", noises, sep = ""),
                     paste("components_", nems, sep = ""),
                     c("mnem", "nem", "cnem", "random2"),
                     c("time", "overfit", "accuracy", "sensitivity",
                       "specificity", "mixing", "mixing2")))

for (i in nem) {
    for (j in noise) {    
        if (file.exists(paste("simres_mnem_", Sgenes, "_", run, "_", j,
                              "_", i, ".rda", sep = ""))) {
            print(paste("simres_mnem_", Sgenes, "_", run, "_", j, "_",
                        i, ".rda", sep = ""))
            stop("simulation result already exists")
        }
    }
}
for (donoise in noise) {
    for (donem in nem) {
        print(paste(rep("_", 100), collapse = ""))
        print(paste("run", run))
        print(paste("noise", noises[donoise]))
        print(paste("nems", nems[donem]))
 
        mw <- runif(nems[donem], 0.1, 1)
        mw <- mw/sum(mw)
        sim <- simData(Sgenes = Sgenes, Egenes = Egenes, nCells = nCells,
                       Nems = nems[donem],
                       mw = mw, uninform = floor(Sgenes*Egenes*0.1))
        simfull <- NULL
        fullsim <- sim$Nem[[1]]*0
        for (i in seq_len(length(sim$Nem))) {
            tmp <- transitive.closure(sim$Nem[[i]], mat = TRUE)
            simfull <- cbind(simfull, t(tmp))
            fullsim <- fullsim + transitive.closure(sim$Nem[[i]], mat = TRUE)
        }
        fullsim[which(fullsim > 1)] <- 1
        diag(fullsim) <- 1
        
        data <- sim$data
        data <- (data - 0.5)/0.5
        data <- data + rnorm(length(sim$data), 0, noises[donoise])

        p <- NULL
        start <- as.numeric(format(Sys.time(), "%s"))
        res <- list()
        if (maxk == 1) {
            res <- mnem(data, starts = starts, search = search,
                        verbose = verbose)
        } else {
            bics <- rep(Inf, maxk)
            for (k in seq_len(maxk)) {
                res[[k]] <- mnem(data, starts = starts, search = search, k = k,
                                 verbose = verbose)
                bics[k] <- getIC(res[[k]])
            }
            res1 <- res[[1]]
            res <- res[[which.min(bics)]]
        }
        simres[run, donoise, donem, 1, 1] <-
            as.numeric(format(Sys.time(), "%s")) - start
        resfull <- NULL
        fullres <- res$comp[[1]]$phi*0
        for (i in seq_len(length(res$comp))) {
            tmp <- transitive.closure(res$comp[[i]]$phi, mat = TRUE)
            resfull <- cbind(resfull, t(tmp))
            fullres <- fullres + transitive.closure(res$comp[[i]]$phi,
                                                    mat = TRUE)
        }
        fullres[which(fullres > 1)] <- 1
        diag(fullres) <- 1

        if (dim(res$probs)[1] == 1) {
            mwbin <- 1
        } else {
            mwbin <- apply(apply(getAffinity(res$probs, mw = res$mw,
                                             affinity=0), 2,
                                 function(x) { xmax <- max(x)
                                     x[which(x != xmax)] <- 0
                                     x[which(x != 0)] <- 1
                                     return(x) }),
                           1, sum)/ncol(res$probs)
        }
        
        simres[run, donoise, donem, 1, 2] <- length(res$comp)/nems[donem]
        tp <- sum(fullres == 1 & fullsim == 1) - ncol(fullres)
        tn <- sum(fullres == 0 & fullsim == 0)
        fp <- sum(fullres == 1 & fullsim == 0)
        fn <- sum(fullres == 0 & fullsim == 1)
        simres[run, donoise, donem, 1, 4] <- tp/(tp+fn)
        simres[run, donoise, donem, 1, 5] <- tn/(tn+fp)
        simres[run, donoise, donem, 1, 3] <- hamSim(simfull, resfull)
        if (length(mw) == length(res$mw)) {
            simres[run, donoise, donem, 1, 6] <- sum(dist(rbind(sort(res$mw),
                                                                sort(mw))))
            simres[run, donoise, donem, 1, 7] <- sum(dist(rbind(sort(mwbin),
                                                                sort(mw))))
        }
        if (length(mw) > length(res$mw)) {
            simres[run, donoise, donem, 1, 6] <-
                sum(dist(rbind(sort(c(res$mw,
                                      rep(0,length(mw) - length(res$mw)))),
                               sort(mw))))
            simres[run, donoise, donem, 1, 7] <-
                sum(dist(rbind(sort(c(mwbin,
                                      rep(0, length(mw) - length(mwbin)))),
                               sort(mw))))
        }
        if (length(mw) < length(res$mw)) {
            simres[run, donoise, donem, 1, 6] <-
                sum(dist(rbind(sort(c(mw,
                                      rep(0, length(res$mw) - length(mw)))),
                               sort(res$mw))))
            simres[run, donoise, donem, 1, 7] <-
                sum(dist(rbind(sort(c(mw,
                                      rep(0, length(mwbin) - length(mw)))),
                               sort(mwbin))))
        }
        
        ## nem:
        start <- as.numeric(format(Sys.time(), "%s"))
        nemres <- mynem(data, search = search)
        simres[run, donoise, donem, 2, 1] <-
            as.numeric(format(Sys.time(), "%s")) - start
        if (maxk == 1) {
            fullnem <- transitive.closure(nemres$adj, mat = TRUE)
        } else {
            fullnem <- transitive.closure(res1$comp[[1]]$phi, mat = TRUE)
        }
        diag(fullnem) <- 1

        simres[run, donoise, donem, 2, 2] <- 1/nems[donem]
        tp <- sum(fullnem == 1 & fullsim == 1) - ncol(fullnem)
        tn <- sum(fullnem == 0 & fullsim == 0)
        fp <- sum(fullnem == 1 & fullsim == 0)
        fn <- sum(fullnem == 0 & fullsim == 1)
        simres[run, donoise, donem, 2, 4] <- tp/(tp+fn)
        simres[run, donoise, donem, 2, 5] <- tn/(tn+fp)
        simres[run, donoise, donem, 2, 3] <- hamSim(simfull, t(fullnem))
        simres[run, donoise, donem, 2, 6] <-
            sum(dist(rbind(sort(c(1, rep(0, length(mw) - 1))), sort(mw))))
        
        ## cluster NEM:
        start <- as.numeric(format(Sys.time(), "%s"))
        res <- clustNEM(data, search = search)
        simres[run, donoise, donem, 3, 1] <-
            as.numeric(format(Sys.time(), "%s")) - start
         resfull <- NULL
        fullres <- res$comp[[1]]$phi*0
        for (i in seq_len(length(res$comp))) {
            tmp <- transitive.closure(res$comp[[i]]$phi, mat = TRUE)
            resfull <- cbind(resfull, t(tmp))
            fullres <- fullres + transitive.closure(res$comp[[i]]$phi,
                                                    mat = TRUE)
        }
        fullres[which(fullres > 1)] <- 1
        diag(fullres) <- 1
        
        simres[run, donoise, donem, 4, 2] <- length(res$comp)/nems[donem]
        tp <- sum(fullrand == 1 & fullsim == 1) - ncol(fullrand)
        tn <- sum(fullrand == 0 & fullsim == 0)
        fp <- sum(fullrand == 1 & fullsim == 0)
        fn <- sum(fullrand == 0 & fullsim == 1)
        simres[run, donoise, donem, 4, 4] <- tp/(tp+fn)
        simres[run, donoise, donem, 4, 5] <- tn/(tn+fp)
        simres[run, donoise, donem, 4, 3] <- hamSim(simfull, fullrand)
        if (length(mw) == length(res$mw)) {
            simres[run, donoise, donem, 1, 6] <- sum(dist(rbind(sort(res$mw),
                                                                sort(mw))))
        }
        if (length(mw) > length(res$mw)) {
            simres[run, donoise, donem, 1, 6] <-
                sum(dist(rbind(sort(c(res$mw,
                                      rep(0, length(mw) - length(res$mw)))),
                               sort(mw))))
        }
        if (length(mw) < length(res$mw)) {
            simres[run, donoise, donem, 1, 6] <-
                sum(dist(rbind(sort(c(mw,
                                      rep(0, length(res$mw) - length(mw)))),
                               sort(res$mw))))
        }
    }
}

end1 <- as.numeric(format(Sys.time(), "%s"))

print(end1 - start1)

for (i in nem) {
    for (j in noise) {    
        save(simres, noises, nems, file = paste("temp/simres_mnem_", Sgenes,
                                                "_", run, "_", j, "_", i,
                                                ".rda", sep = ""))
    }
}

stop("simulations are done")

sim <- list()

count <- 0
for (Sgenes in c(3,5,10,20)) {
    simresF <- NULL
    for (i in seq_len(length(noises))) {
        for (j in seq_len(length(nems))) {
            for (k in seq_len(runs)) {
                if (file.exists(paste0("simres_mnem_", Sgenes, "_", k, "_",
                                       i, "_", j, ".rda"))) {
                    load(paste0("simres_mnem_", Sgenes, "_", k, "_", i,
                                "_", j, ".rda"))
                    if (is.null(simresF)) {
                        simresF <- simres
                    } else {
                        simresF[k,i,j,,] <- simres[k,i,j,,]
                    }
                }
            }
        }
    }
    assign(paste0("simres", Sgenes), simresF)
    count <- count + 1
    sim[[count]] <- simresF
}

library(mnem)
library(cluster)
library(nem)
library(Rgraphviz)

## define dataset

datasets <- c("cropseq", "perturbseq_cc7d", "perturbseq_p7d")
dataset <- datasets[1]

args <- commandArgs()

dataset <- gsub("dataset=", "", args[grep("dataset=", args)])

parallel <- gsub("cores=", "", args[grep("cores=", args)])

starts <- gsub("starts=", "", args[grep("starts=", args)])

run <- gsub("run=", "", args[grep("run=", args)])

dollr <- as.numeric(gsub("dollr=", "", args[grep("dollr=", args)]))

dobig <- as.numeric(gsub("dobig=", "", args[grep("dobig=", args)]))

dosmall <- as.numeric(gsub("dosmall=", "", args[grep("dosmall=", args)]))

addendum <- paste0("_run", run)

library(snowfall)

maxk <- 5

print(dataset)
print(dobig)
print(dosmall)
print(dollr)

if (dollr) {

    load(paste0(dataset, "_data.rda"))

    if (length(grep("perturbseq", dataset)) == 0) {

        exprslvl <- apply(data, 1, median)
        
        data <- data[which(exprslvl > 0), ]

        data <- t(t(data)/(colSums(data)/10000))

        data <- log2(data + 0.5)
    
    } else {

        data <- exp(data) - 1

        exprslvl <- apply(data, 1, median)
        
        data <- data[which(exprslvl > 0), ]

        if (length(grep("p7d|cc7d", dataset)) > 0) {

            colnames(data)[grep("INTER", colnames(data))] <- ""

        }

        data <- log2(data + 0.5)

    }

    llr <- data*0

    C <- which(colnames(data) %in% "")

    distrPar <- function(i, data, C) {
        llrcol <- numeric(ncol(data))
        for (j in which(!(colnames(data) %in% ""))) {
            gene <- colnames(data)[j]
            D <- which(colnames(data) %in% gene)
            cdistr <- ecdf(data[i, C])
            ddistr <- ecdf(data[i, D])
            llrcol[j] <-
                log2(min(ddistr(data[i, j]),
                         1 - ddistr(data[i, j]))/min(cdistr(data[i,j]),
                                                     1 - cdistr(data[i,j])))
        }
        return(llrcol)
    }

    sfInit(parallel = TRUE, cpus = parallel)
    llr <- sfLapply(1:nrow(data), distrPar, data, C)
    llr <- do.call("rbind", llr)
    sfStop()

    llr[is.na(llr)] <- 0

    llr[is.infinite(llr)] <- max(llr[!is.infinite(llr)])

    colnames(llr) <- colnames(data)

    llr <- llr[, which(!(colnames(data) %in% ""))]

    rownames(llr) <- rownames(data)

    save(llr, file = paste0(dataset, "_llr.rda"))

    print("llr done")

}

if (dosmall) {

    load(paste0(dataset, "_kegg.rda"))
    load(paste0(dataset, "_llr.rda"))

    if (length(grep("perturbseq", dataset)) == 0) {

        llr <- llr[, -grep("DHODH|MVD|TUBB", colnames(llr))]


    }

    llr <- t(apply(llr, 1, function(x) {
        x[is.infinite(x)] <- max(x[!is.infinite(x)])
        return(x)
    }))

    colnames(llr) <- toupper(colnames(llr))

    if (length(grep("perturbseq", dataset)) == 0) {

        cropgenes <- c("LCK", "ZAP70", "PTPN6", "DOK2", "PTPN11", "EGR3", "LAT")
        
        lods <- llr[, which(colnames(llr) %in% cropgenes)]
        
    } else {
        
        lods <- llr
        
    }

    badgenes <- "Tcrlibrary"
    badgenes <- grep(badgenes, rownames(lods))

    if (length(badgenes) > 0) {
        lods <- lods[-badgenes, ]
    }

    sdev <- apply(lods, 1, sd)

    lods <- lods[which(sdev > sd(lods)), ]

    n <- length(unique(colnames(lods)))

    lods <- lods

    bics <- rep(Inf, maxk)

    res <- list()
    
    for (k in seq_len(maxk)) {

        res[[k]] <- mnem(lods, starts = starts, type = "random",
                         parallel = parallel, k = k, verbose = TRUE,
                         converged = 10^-1, search = "modules")
        
        res[[k]]$data <- NULL
        
        save(res, file = paste0(dataset, "_mnem_small", addendum,
                                ".rda"))
        
    }
    
    save(res, file = paste0(dataset, "_mnem_small", addendum,
                            ".rda"))

    stop("small set done")

}

datasets <- c("cropseq", "perturbseq_cc7d", "perturbseq_p7d")
dataset <- datasets[1]

maxk <- 5

starts <- 100

bigorsmall <- "small"

lls <- matrix(0, 5, starts)

llmins <- matrix(0, 5, starts)

resMax <- list()

for (i in seq_len(starts)) {
    print(i)
    if (file.exists(paste0(
                           dataset, "_mnem_", bigorsmall, "_run", i, ".rda"))) {
        load(paste0(
                    dataset, "_mnem_", bigorsmall, "_run", i, ".rda"))
    } else {
        next()
    }
    lls[1, i] <- res[[1]]$ll
    for (j in seq_len(min(maxk, length(res)))) {
        lls[j, i] <- res[[j]]$ll
        llmins[j, i] <- min(res[[j]]$limits[[1]]$ll)
        if (i == 1 | length(resMax) < j) {
            resMax[[j]] <- res[[j]]
        } else {
            if (resMax[[j]]$ll < res[[j]]$ll) {
                resMax[[j]] <- res[[j]]
            }
        }
    }
}

res <- resMax

res[[5]]$data <- res[[4]]$data <-
    res[[3]]$data <- res[[2]]$data <- res[[1]]$data <- lods

load(paste0(dataset, "_mnem_", bigorsmall, "_final.rda"))

cropres <- res

cc7dres <- res

p7dres <- res

res2 <- list(cropres, cc7dres, p7dres)

for (i in 1:3) {
    res2[[i]][[1]]$data <- res2[[i]][[1]]$data[1:2, ]
    for (j in 2:5) {
        res2[[i]][[j]]$data <- NULL
    }
}
```